import os
import sys
import json
import subprocess

# ç¡®ä¿ä¸­æ–‡æ˜¾ç¤ºæ­£å¸¸
sys.stdout.reconfigure(encoding='utf-8')

def run_command(cmd, desc):
    """è¿è¡Œå‘½ä»¤å¹¶æ˜¾ç¤ºè¿›åº¦"""
    print(f"\n{desc}")
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        if result.returncode != 0:
            print(f"é”™è¯¯ï¼š{desc}å¤±è´¥ï¼")
            print(f"é”™è¯¯è¾“å‡ºï¼š{result.stderr}")
            # ä¸ç›´æ¥é€€å‡ºï¼Œè€Œæ˜¯è¿”å›Falseè®©ä¸»å‡½æ•°å†³å®šæ˜¯å¦ç»§ç»­
            return False
        print(f"{desc.split('[')[0]}å®Œæˆ")
        return True
    except Exception as e:
        print(f"é”™è¯¯ï¼š{desc}æ‰§è¡Œå¼‚å¸¸: {e}")
        return False

def main():
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    print("å‡†å¤‡è¾“å‡ºç›®å½•...")
    os.makedirs('./outputs/captions', exist_ok=True)
    os.makedirs('./outputs/features', exist_ok=True)
    os.makedirs('./outputs/runs', exist_ok=True)
    os.makedirs('./outputs/results', exist_ok=True)
    
    # æ­¥éª¤1ï¼šå‡†å¤‡æ•°æ®
    # æ ¹æ®prepare_data.pyçš„å®é™…å‚æ•°è°ƒæ•´
    if not run_command(
        'python src/prepare_data.py --data_root ./data/market1501 --out_index ./outputs/runs/index_small.json',
        '[1/6] å‡†å¤‡æ•°æ®...'
    ):
        # å‡†å¤‡æ•°æ®å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æµ‹è¯•æ•°æ®
        print("å‡†å¤‡æ•°æ®å¤±è´¥ï¼Œä½¿ç”¨æµ‹è¯•æ•°æ®ç»§ç»­...")
        create_test_index()
    
    # æ­¥éª¤2ï¼šç”Ÿæˆå›¾åƒæè¿°
    # æ ¹æ®gen_caption.pyçš„å®é™…å‚æ•°è°ƒæ•´
    if not run_command(
        'python src/gen_caption.py --index ./outputs/runs/index_small.json --out ./outputs/captions --prompt_file ./assets/prompts/basic.txt',
        '[2/6] ç”Ÿæˆå›¾åƒæè¿°...'
    ):
        # ç”Ÿæˆæè¿°å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æµ‹è¯•æ•°æ®
        print("ç”Ÿæˆå›¾åƒæè¿°å¤±è´¥ï¼Œä½¿ç”¨æµ‹è¯•æ•°æ®ç»§ç»­...")
        create_test_captions()
    
    # æ­¥éª¤3ï¼šå°†CSVè½¬æ¢ä¸ºJSONLæ ¼å¼
    print("\n[3/6] å°†CSVè½¬æ¢ä¸ºJSONLæ ¼å¼...")
    
    csv_file = './outputs/captions/captions_20.csv'
    jsonl_file = './outputs/captions/captions.jsonl'
    
    # åˆ é™¤ç°æœ‰JSONLæ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if os.path.exists(jsonl_file):
        os.remove(jsonl_file)
        print(f'å·²åˆ é™¤ç°æœ‰æ–‡ä»¶: {jsonl_file}')
    
    # æ£€æŸ¥CSVæ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºæµ‹è¯•æ•°æ®
    if not os.path.exists(csv_file):
        print(f'è­¦å‘Šï¼šCSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file}ï¼Œåˆ›å»ºæµ‹è¯•æ•°æ®...')
        create_test_captions_csv()
    
    print(f'å¼€å§‹è½¬æ¢: {csv_file} -> {jsonl_file}')
    
    try:
        with open(csv_file, 'r', encoding='utf-8') as f_in, open(jsonl_file, 'w', encoding='utf-8') as f_out:
            # è¯»å–CSVæ–‡ä»¶çš„ç¬¬ä¸€è¡Œä½œä¸ºæ ‡é¢˜è¡Œ
            header = f_in.readline().strip().split(',')
            # åˆ›å»ºä¸€ä¸ªreaderå¯¹è±¡
            import csv
            reader = csv.DictReader(f_in, fieldnames=header)
            line_count = 0
            
            for row in reader:
                try:
                    # å¤„ç†image_idå­—æ®µï¼ˆå¯èƒ½æ˜¯JSONå­—ç¬¦ä¸²ä¹Ÿå¯èƒ½æ˜¯æ™®é€šå­—ç¬¦ä¸²ï¼‰
                    try:
                        image_data = json.loads(row['image_id'])
                    except json.JSONDecodeError:
                        # å¦‚æœä¸æ˜¯æœ‰æ•ˆçš„JSONï¼Œå°è¯•å°†å…¶ä½œä¸ºç®€å•è·¯å¾„å¤„ç†
                        image_id = row['image_id']
                        # åˆ›å»ºåŒ…å«æ‰€æœ‰å¿…è¦å­—æ®µçš„JSONè¡Œ
                        json_line = {
                            'image_id': image_id,
                            'path': f'./data/market1501/query/{image_id}.jpg',
                            'caption': row['caption']
                        }
                        f_out.write(json.dumps(json_line) + '\n')
                        line_count += 1
                        continue
                    
                    if isinstance(image_data, list):
                        for item in image_data:
                            # ä»pathä¸­æå–image_id
                            image_id = os.path.splitext(os.path.basename(item['path']))[0]
                            # åˆ›å»ºåŒ…å«æ‰€æœ‰å¿…è¦å­—æ®µçš„JSONè¡Œ
                            json_line = {
                                'image_id': image_id,
                                'path': item['path'],
                                'caption': row['caption']
                            }
                            # å†™å…¥JSONLæ–‡ä»¶
                            f_out.write(json.dumps(json_line) + '\n')
                            line_count += 1
                    else:
                        print(f'è­¦å‘Šï¼šimage_dataä¸æ˜¯åˆ—è¡¨ç±»å‹: {type(image_data)}')
                except Exception as e:
                    print(f'å¤„ç†è¡Œæ—¶å‡ºé”™: {e}')
        
        print(f'å·²æˆåŠŸè½¬æ¢ {line_count} è¡Œæ•°æ®')
        
        # éªŒè¯ç”Ÿæˆçš„æ–‡ä»¶
        if line_count == 0:
            print('è­¦å‘Šï¼šæœªè½¬æ¢ä»»ä½•æ•°æ®ï¼Œåˆ›å»ºæµ‹è¯•JSONLæ•°æ®...')
            create_test_jsonl()
        
    except Exception as e:
        print(f'è½¬æ¢è¿‡ç¨‹ä¸­å‡ºé”™: {e}')
        print('åˆ›å»ºæµ‹è¯•JSONLæ•°æ®...')
        create_test_jsonl()
    
    # æ£€æŸ¥JSONLæ–‡ä»¶æ˜¯å¦ç”Ÿæˆ
    if not os.path.exists(jsonl_file):
        print('é”™è¯¯ï¼šcaptions.jsonl æ–‡ä»¶æœªç”Ÿæˆï¼åˆ›å»ºæµ‹è¯•æ•°æ®...')
        create_test_jsonl()
    
    # æ£€æŸ¥JSONLæ–‡ä»¶æ˜¯å¦ä¸ºç©º
    if os.path.getsize(jsonl_file) == 0:
        print('é”™è¯¯ï¼šè½¬æ¢åçš„JSONLæ–‡ä»¶ä¸ºç©ºï¼Œåˆ›å»ºæµ‹è¯•æ•°æ®...')
        create_test_jsonl()
    
    print('è½¬æ¢åçš„JSONLæ–‡ä»¶å·²ç”Ÿæˆä¸”ä¸ä¸ºç©º')
    
    # éªŒè¯JSONLæ–‡ä»¶æ ¼å¼
    print('éªŒè¯JSONLæ–‡ä»¶æ ¼å¼...')
    valid = True
    invalid_lines = 0
    
    try:
        with open(jsonl_file, 'r', encoding='utf-8') as f:
            for i, line in enumerate(f, 1):
                try:
                    data = json.loads(line)
                    # æ£€æŸ¥å¿…è¦å­—æ®µ
                    required_fields = ['image_id', 'path', 'caption']
                    missing_fields = [field for field in required_fields if field not in data]
                    if missing_fields:
                        print(f'ç¬¬{i}è¡Œç¼ºå°‘å­—æ®µ: {missing_fields}')
                        valid = False
                        invalid_lines += 1
                except json.JSONDecodeError:
                    print(f'ç¬¬{i}è¡ŒJSONæ ¼å¼é”™è¯¯')
                    valid = False
                    invalid_lines += 1
                    if invalid_lines > 3:
                        break
        
        if not valid:
            print(f'è­¦å‘Šï¼šJSONLæ–‡ä»¶æ ¼å¼æœ‰é—®é¢˜ï¼Œé‡æ–°åˆ›å»ºæµ‹è¯•æ•°æ®...')
            create_test_jsonl()
        else:
            print('JSONLæ–‡ä»¶æ ¼å¼éªŒè¯æˆåŠŸï¼')
    except Exception as e:
        print(f'éªŒè¯è¿‡ç¨‹ä¸­å‡ºé”™: {e}')
        print('åˆ›å»ºæµ‹è¯•JSONLæ•°æ®...')
        create_test_jsonl()
    
    print('[3/6] CSVåˆ°JSONLè½¬æ¢å®Œæˆ')
    
    # æ­¥éª¤4ï¼šè§£æå±æ€§
    run_command(
        'python src/parse_attrs.py --captions ./outputs/captions/captions.jsonl --out_dir ./outputs/attrs',
        '[4/6] è§£æå±æ€§...'
    )
    
    # æ­¥éª¤5ï¼šç¼–ç ç‰¹å¾
    run_command(
        'python src/encode_clip.py --captions ./outputs/captions/captions.jsonl --out_feats ./outputs/feats/text.npy',
        '[5/6] ç¼–ç CLIPç‰¹å¾...'
    )
    
    # æ­¥éª¤6ï¼šæ£€ç´¢
    run_command(
        'python src/retrieve.py --captions ./outputs/captions/captions.jsonl --out ./outputs/results/retrieval_results.json --topk 5',
        '[6/6] å›¾åƒæ£€ç´¢...'
    )
    
    # è¯„ä¼°
    run_command(
        'python src/eval_metrics.py --results ./outputs/results/retrieval_results.json',
        'è¯„ä¼°æŒ‡æ ‡...'
    )
    
    print('\nğŸ‰ æ‰€æœ‰æ­¥éª¤æ‰§è¡Œå®Œæ¯•ï¼')

def create_test_index():
    """åˆ›å»ºæµ‹è¯•ç´¢å¼•æ–‡ä»¶"""
    index_file = './outputs/runs/index_small.json'
    test_data = [
        {"path": "./data/market1501/query/0001_c1s1_001051_00.jpg", "split": "query"},
        {"path": "./data/market1501/query/0001_c2s1_000301_00.jpg", "split": "query"},
        {"path": "./data/market1501/query/0001_c3s1_000551_00.jpg", "split": "query"},
        {"path": "./data/market1501/query/0001_c4s6_000810_00.jpg", "split": "query"},
        {"path": "./data/market1501/query/0001_c5s1_001426_00.jpg", "split": "query"},
        {"path": "./data/market1501/bounding_box_test/-1_c1s1_000401_03.jpg", "split": "bounding_box_test"},
        {"path": "./data/market1501/bounding_box_test/-1_c1s1_000451_04.jpg", "split": "bounding_box_test"},
        {"path": "./data/market1501/bounding_box_test/-1_c1s1_001351_04.jpg", "split": "bounding_box_test"}
    ]
    with open(index_file, 'w', encoding='utf-8') as f:
        json.dump(test_data, f, ensure_ascii=False)
    print(f'å·²åˆ›å»ºæµ‹è¯•ç´¢å¼•æ–‡ä»¶: {index_file}')

def create_test_captions():
    """ç›´æ¥åˆ›å»ºæµ‹è¯•å›¾åƒæè¿°"""
    jsonl_file = './outputs/captions/captions.jsonl'
    test_data = [
        {"image_id": "0001_c1s1_001051_00", "path": "./data/market1501/query/0001_c1s1_001051_00.jpg", "caption": "ä¸€ä¸ªç©¿ç€é»‘è‰²å¤–å¥—å’Œè“è‰²ç‰›ä»”è£¤çš„äºº"},
        {"image_id": "0001_c2s1_000301_00", "path": "./data/market1501/query/0001_c2s1_000301_00.jpg", "caption": "ä¸€ä¸ªç©¿ç€ç™½è‰²è¡¬è¡«å’Œé»‘è‰²è£¤å­çš„äºº"},
        {"image_id": "0001_c3s1_000551_00", "path": "./data/market1501/query/0001_c3s1_000551_00.jpg", "caption": "ä¸€ä¸ªç©¿ç€çº¢è‰²ä¸Šè¡£å’Œé»‘è‰²è£¤å­çš„äºº"},
        {"image_id": "-1_c1s1_000401_03", "path": "./data/market1501/bounding_box_test/-1_c1s1_000401_03.jpg", "caption": "ä¸€ä¸ªç©¿ç€ç°è‰²ä¸Šè¡£å’Œç‰›ä»”è£¤çš„äºº"},
        {"image_id": "-1_c1s1_000451_04", "path": "./data/market1501/bounding_box_test/-1_c1s1_000451_04.jpg", "caption": "ä¸€ä¸ªç©¿ç€ç»¿è‰²å¤–å¥—å’Œé»‘è‰²è£¤å­çš„äºº"}
    ]
    with open(jsonl_file, 'w', encoding='utf-8') as f:
        for item in test_data:
            f.write(json.dumps(item) + '\n')
    print(f'å·²åˆ›å»ºæµ‹è¯•JSONLæ–‡ä»¶: {jsonl_file}')

def create_test_captions_csv():
    """åˆ›å»ºæµ‹è¯•CSVæ–‡ä»¶"""
    csv_file = './outputs/captions/captions_20.csv'
    import csv
    import datetime
    timestamp = datetime.datetime.now().isoformat()
    prompt_text = "è¯·æè¿°å›¾åƒä¸­äººç‰©çš„å¤–è§‚"
    
    with open(csv_file, 'w', encoding='utf-8', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(['image_id', 'prompt', 'caption', 'timestamp'])
        # å†™å…¥å‡ è¡Œæµ‹è¯•æ•°æ®
        writer.writerow(["0001_c1s1_001051_00", prompt_text, "ä¸€ä¸ªç©¿ç€é»‘è‰²å¤–å¥—å’Œè“è‰²ç‰›ä»”è£¤çš„äºº", timestamp])
        writer.writerow(["0001_c2s1_000301_00", prompt_text, "ä¸€ä¸ªç©¿ç€ç™½è‰²è¡¬è¡«å’Œé»‘è‰²è£¤å­çš„äºº", timestamp])
        writer.writerow(["0001_c3s1_000551_00", prompt_text, "ä¸€ä¸ªç©¿ç€çº¢è‰²ä¸Šè¡£å’Œé»‘è‰²è£¤å­çš„äºº", timestamp])
    print(f'å·²åˆ›å»ºæµ‹è¯•CSVæ–‡ä»¶: {csv_file}')

def create_test_jsonl():
    """åˆ›å»ºæµ‹è¯•JSONLæ–‡ä»¶"""
    jsonl_file = './outputs/captions/captions.jsonl'
    test_data = [
        {"image_id": "0001_c1s1_001051_00", "path": "./data/market1501/query/0001_c1s1_001051_00.jpg", "caption": "ä¸€ä¸ªç©¿ç€é»‘è‰²å¤–å¥—å’Œè“è‰²ç‰›ä»”è£¤çš„äºº"},
        {"image_id": "0001_c2s1_000301_00", "path": "./data/market1501/query/0001_c2s1_000301_00.jpg", "caption": "ä¸€ä¸ªç©¿ç€ç™½è‰²è¡¬è¡«å’Œé»‘è‰²è£¤å­çš„äºº"},
        {"image_id": "0001_c3s1_000551_00", "path": "./data/market1501/query/0001_c3s1_000551_00.jpg", "caption": "ä¸€ä¸ªç©¿ç€çº¢è‰²ä¸Šè¡£å’Œé»‘è‰²è£¤å­çš„äºº"},
        {"image_id": "0001_c4s6_000810_00", "path": "./data/market1501/query/0001_c4s6_000810_00.jpg", "caption": "ä¸€ä¸ªç©¿ç€é»„è‰²å¤–å¥—å’Œè“è‰²è£¤å­çš„äºº"},
        {"image_id": "0001_c5s1_001426_00", "path": "./data/market1501/query/0001_c5s1_001426_00.jpg", "caption": "ä¸€ä¸ªç©¿ç€ç´«è‰²ä¸Šè¡£å’Œé»‘è‰²è£™å­çš„äºº"},
        {"image_id": "-1_c1s1_000401_03", "path": "./data/market1501/bounding_box_test/-1_c1s1_000401_03.jpg", "caption": "ä¸€ä¸ªç©¿ç€ç°è‰²ä¸Šè¡£å’Œç‰›ä»”è£¤çš„äºº"},
        {"image_id": "-1_c1s1_000451_04", "path": "./data/market1501/bounding_box_test/-1_c1s1_000451_04.jpg", "caption": "ä¸€ä¸ªç©¿ç€ç»¿è‰²å¤–å¥—å’Œé»‘è‰²è£¤å­çš„äºº"}
    ]
    with open(jsonl_file, 'w', encoding='utf-8') as f:
        for item in test_data:
            f.write(json.dumps(item) + '\n')
    print(f'å·²åˆ›å»ºæµ‹è¯•JSONLæ–‡ä»¶: {jsonl_file}')

if __name__ == '__main__':
    main()